{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b40e75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:27.105910Z",
     "iopub.status.busy": "2023-08-11T07:38:27.105002Z",
     "iopub.status.idle": "2023-08-11T07:38:43.478545Z",
     "shell.execute_reply": "2023-08-11T07:38:43.477261Z"
    },
    "papermill": {
     "duration": 16.38348,
     "end_time": "2023-08-11T07:38:43.480931",
     "exception": false,
     "start_time": "2023-08-11T07:38:27.097451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/pip-packages-icr/pip-packages\r\n",
      "Processing /kaggle/input/pip-packages-icr/pip-packages/tabpfn-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.23.5)\r\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (6.0)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.31.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.2.2)\r\n",
      "Requirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2023.5.7)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (3.1.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\r\n",
      "Installing collected packages: tabpfn\r\n",
      "Successfully installed tabpfn-0.1.9\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n",
    "!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41764158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:43.497620Z",
     "iopub.status.busy": "2023-08-11T07:38:43.496066Z",
     "iopub.status.idle": "2023-08-11T07:38:50.636638Z",
     "shell.execute_reply": "2023-08-11T07:38:50.635661Z"
    },
    "papermill": {
     "duration": 7.151046,
     "end_time": "2023-08-11T07:38:50.639364",
     "exception": false,
     "start_time": "2023-08-11T07:38:43.488318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import Joblib Module from Scikit Learn\n",
    "import joblib\n",
    "\n",
    "import numpy as np                       # NumPy for numerical computations\n",
    "import pandas as pd                      # Pandas for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, normalize   # LabelEncoder for encoding categorical variables, normalize for feature scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier   # GradientBoostingClassifier and RandomForestClassifier for classification models\n",
    "from tabpfn import TabPFNClassifier \n",
    "import xgboost   # XGBoost for gradient boosting models\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score   # accuracy_score for evaluating model performance\n",
    "from sklearn.impute import SimpleImputer   # SimpleImputer for handling missing values\n",
    "import imblearn   # imblearn for imbalanced dataset handling\n",
    "from imblearn.over_sampling import RandomOverSampler   # RandomOverSampler for oversampling minority class\n",
    "from imblearn.under_sampling import RandomUnderSampler   # RandomUnderSampler for undersampling majority class\n",
    "import inspect   # inspect for retrieving information about live objects\n",
    "from collections import defaultdict   # defaultdict for creating a dictionary with default values\n",
    "import warnings   # warnings for ignoring warnings during runtime\n",
    "from sklearn.model_selection import KFold as KF\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce613a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:50.654675Z",
     "iopub.status.busy": "2023-08-11T07:38:50.654012Z",
     "iopub.status.idle": "2023-08-11T07:38:50.658691Z",
     "shell.execute_reply": "2023-08-11T07:38:50.657663Z"
    },
    "papermill": {
     "duration": 0.01489,
     "end_time": "2023-08-11T07:38:50.661172",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.646282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb3e35",
   "metadata": {
    "papermill": {
     "duration": 0.006343,
     "end_time": "2023-08-11T07:38:50.674048",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.667705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c4c7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:50.688460Z",
     "iopub.status.busy": "2023-08-11T07:38:50.688196Z",
     "iopub.status.idle": "2023-08-11T07:38:50.698380Z",
     "shell.execute_reply": "2023-08-11T07:38:50.697525Z"
    },
    "papermill": {
     "duration": 0.019514,
     "end_time": "2023-08-11T07:38:50.700312",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.680798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepair_test(df):\n",
    "    #take 'Id' column and drop 'Id', 'EJ' columns\n",
    "    Id = df['Id']\n",
    "    test = df.drop(['Id', 'EJ'], axis=1)\n",
    "    columns = test.columns\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values = np.nan, strategy ='median')\n",
    "    imputer = imputer.fit(test)\n",
    "    test = imputer.transform(test)\n",
    "    test = pd.DataFrame(test, columns = columns)\n",
    "    return Id, test\n",
    "\n",
    "def prepair_input(df, classi):\n",
    "    columns = df.columns\n",
    "    \n",
    "    # Convert the values in the 'EJ' column of the 'test' dataframe to binary values (0 or 1),\n",
    "    # based on the occurrence of the 'first_category' in the 'train' dataframe\n",
    "#     first_category = df.EJ.unique()[0]\n",
    "#     df.EJ = df.EJ.eq(first_category).astype('int')\n",
    "\n",
    "    df = df.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'})\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values = np.nan, strategy ='median')\n",
    "    imputer = imputer.fit(df)\n",
    "    df = imputer.transform(df)\n",
    "    df = pd.DataFrame(df, columns = columns)\n",
    "    \n",
    "    # Create a RandomOverSampler object with a random state of 42\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    # Resample the 'train_pred_and_time' dataframe and 'greeks.Alpha' series using RandomOverSampler\n",
    "    # The resampled data is assigned to 'train_ros' and 'y_ros' respectively\n",
    "    x_ros, y_ros = ros.fit_resample(df, classi)\n",
    "    return x_ros, y_ros\n",
    "\n",
    "def normolized(df):\n",
    "    columns = df.columns\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    model = scaler.fit(df)\n",
    "    scaled_df = model.transform(df)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaled_df, columns = columns)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66ea51",
   "metadata": {
    "papermill": {
     "duration": 0.006374,
     "end_time": "2023-08-11T07:38:50.713134",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.706760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Balanced Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ee4209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:50.728322Z",
     "iopub.status.busy": "2023-08-11T07:38:50.726923Z",
     "iopub.status.idle": "2023-08-11T07:38:50.734059Z",
     "shell.execute_reply": "2023-08-11T07:38:50.733202Z"
    },
    "papermill": {
     "duration": 0.016272,
     "end_time": "2023-08-11T07:38:50.735956",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.719684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    #number of true values of 0 & 1\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # calculate the weights for each class to balance classes\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "    # calculate the predicted probabilities for each class\n",
    "    p_0 = np.clip(y_pred[:, 0], 1e-15, 1 - 1e-15)\n",
    "    p_1 = np.clip(y_pred[:, 1], 1e-15, 1 - 1e-15)\n",
    "    # calculate the summed log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "    # calculate the weighted summed logarithmic loss\n",
    "    # (factgor of 2 included to give same result as LL with balanced input)\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "    # return the average log loss\n",
    "    return balanced_log_loss/(N_0+N_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848dea08",
   "metadata": {
    "papermill": {
     "duration": 0.006332,
     "end_time": "2023-08-11T07:38:50.748882",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.742550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be7c887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:50.764256Z",
     "iopub.status.busy": "2023-08-11T07:38:50.762871Z",
     "iopub.status.idle": "2023-08-11T07:38:51.137595Z",
     "shell.execute_reply": "2023-08-11T07:38:51.136082Z"
    },
    "papermill": {
     "duration": 0.384455,
     "end_time": "2023-08-11T07:38:51.139833",
     "exception": false,
     "start_time": "2023-08-11T07:38:50.755378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "tabpfn = TabPFNClassifier(N_ensemble_configurations=12)\n",
    "\n",
    "config = [\n",
    "    {'name': 'xgb', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'n_estimators': 100 , 'max_depth': 3, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.85},\n",
    "    {'name': 'xgb', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'n_estimators': 200 , 'max_depth': 5, 'learning_rate': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.85},\n",
    "    {'name': 'tabpfn', 'device': 'cuda', 'N_ensemble_configurations': 12},\n",
    "    {'name': 'tabpfn', 'device': 'cuda', 'N_ensemble_configurations': 24},\n",
    "    {'name': 'randomforest', 'n_estimators': 100, 'max_depth': 3, 'random_state': 42}\n",
    "#     {'name': 'randomforest', 'n_estimators': 200, 'max_depth': 5, 'random_state': 42},\n",
    "#     {'name': 'gaussiannb'},\n",
    "#     {'name': 'multinomialnb'},\n",
    "#     {'name': 'kneighbors'},\n",
    "#     {'name': 'gradientboosting'}\n",
    "]\n",
    "\n",
    "def config_classifiers(config):\n",
    "    CLASSIFIER_CLASSES = {\n",
    "        'xgb': XGBClassifier,\n",
    "        'tabpfn': TabPFNClassifier,\n",
    "        'randomforest': RandomForestClassifier,\n",
    "        'gaussiannb': GaussianNB,\n",
    "        'multinomialnb': MultinomialNB,\n",
    "        'kneighbors': KNeighborsClassifier,\n",
    "        'gradientboosting': GradientBoostingClassifier\n",
    "    }\n",
    "\n",
    "    thismodule = sys.modules[__name__]\n",
    "    classifiers = []\n",
    "    for sub_cfg in config:\n",
    "    #     cls = globals()[sub_cfg['name']]\n",
    "        cls = CLASSIFIER_CLASSES[sub_cfg['name']]\n",
    "        print('cls:', cls)\n",
    "        kwargs = {k:v for k, v in sub_cfg.items() if k != 'name'}\n",
    "        classifier = cls(**kwargs)\n",
    "        classifiers.append(classifier)\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28562a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:51.156066Z",
     "iopub.status.busy": "2023-08-11T07:38:51.154658Z",
     "iopub.status.idle": "2023-08-11T07:38:51.164030Z",
     "shell.execute_reply": "2023-08-11T07:38:51.163175Z"
    },
    "papermill": {
     "duration": 0.019218,
     "end_time": "2023-08-11T07:38:51.165966",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.146748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self):\n",
    "        self.classifiers = config_classifiers(config)\n",
    "        print(self.classifiers)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for classifier in self.classifiers:\n",
    "            print(classifier)\n",
    "            if (type(classifier) == type(tabpfn)):\n",
    "                classifier.fit(X, y, overwrite_warning=True)\n",
    "            else :\n",
    "                classifier.fit(X, y)\n",
    "     \n",
    "    def predict_proba(self, x):\n",
    "        # N_models * N_rows * N_classes (#models * 5 * 4)\n",
    "        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n",
    "        averaged_probabilities = np.mean(probabilities, axis=0) # N_rows * N_classes\n",
    "        class_0_est_instances = averaged_probabilities[:, 0].sum()  # N_rows\n",
    "        others_est_instances = averaged_probabilities[:, 1:].sum()  # N_rows   \n",
    "        # Weighted probabilities based on class imbalance\n",
    "        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n",
    "        ret =  new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1) \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569c2d0",
   "metadata": {
    "papermill": {
     "duration": 0.006593,
     "end_time": "2023-08-11T07:38:51.179280",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.172687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e612c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:51.193749Z",
     "iopub.status.busy": "2023-08-11T07:38:51.193468Z",
     "iopub.status.idle": "2023-08-11T07:38:51.200000Z",
     "shell.execute_reply": "2023-08-11T07:38:51.199126Z"
    },
    "papermill": {
     "duration": 0.016067,
     "end_time": "2023-08-11T07:38:51.202019",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.185952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_prob(probs, shape, thres_1, thres_0):\n",
    "#     print('TYPE:', probs.shape, type(probs))\n",
    "    \n",
    "    #transfer to probabilitiy of 2 class: 0 & 1\n",
    "    class_0_prob = probs[:, 0]\n",
    "    others_prob = probs[:, 1:].sum(axis=1)\n",
    "    class_0_prob = class_0_prob.reshape((shape, 1))\n",
    "    others_prob = others_prob.reshape((shape, 1))\n",
    "    \n",
    "#     probs = np.concatenate([class_0_prob, others_prob], axis=-1)\n",
    "#     ret = probs.copy()\n",
    "    col_0 = class_0_prob.copy()\n",
    "    col_0[class_0_prob < thres_1] = 0.0\n",
    "    col_0[class_0_prob > thres_0] = 1.0\n",
    "    col_1 = 1.0 - col_0\n",
    "    ret = np.concatenate([col_0, col_1], axis = -1)\n",
    "#     print('ret', type(ret))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4ff59",
   "metadata": {
    "papermill": {
     "duration": 0.006724,
     "end_time": "2023-08-11T07:38:51.215320",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.208596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc28f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:51.229722Z",
     "iopub.status.busy": "2023-08-11T07:38:51.229451Z",
     "iopub.status.idle": "2023-08-11T07:38:51.239048Z",
     "shell.execute_reply": "2023-08-11T07:38:51.238029Z"
    },
    "papermill": {
     "duration": 0.019455,
     "end_time": "2023-08-11T07:38:51.241407",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.221952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    splits = 5   # Total number of splits for the inner cross-validation\n",
    "    models = []   # List to store the trained models for each inner fold\n",
    "    thres_lst = []\n",
    "    loss_lst = []\n",
    "    pred_sets = []\n",
    "    true_sets = []\n",
    "\n",
    "    # Loop over the splits of the inner cross-validation using tqdm for progress visualization\n",
    "    for split in range(splits):\n",
    "        model = Ensemble()\n",
    "        print('fold', split)\n",
    "        #loading train & test dataset for each fold\n",
    "        save_dir = f'/kaggle/input/icr-kfold5/kfold/fold{split}'\n",
    "\n",
    "        # x_train & y_train\n",
    "        df_train = pd.read_csv(os.path.join(save_dir, 'train.csv'))\n",
    "        x_train = df_train.drop(['Class', 'Alpha'], axis=1)\n",
    "        y_train = df_train.Alpha\n",
    "        #labael-encoder\n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(y_train)\n",
    "        # pre-processing\n",
    "        x_train, y_train = prepair_input(x_train, y_train)\n",
    "\n",
    "        # x_val & y_val\n",
    "        df_val = pd.read_csv(os.path.join(save_dir, 'val.csv'))\n",
    "        x_val = df_val.drop(['Class'], axis=1)\n",
    "        y_val = df_val.Class\n",
    "        print(y_val.value_counts())\n",
    "\n",
    "        #fitting model\n",
    "        model.fit(x_train, y_train)   # Fit the model on the training data\n",
    "        models.append(model)   # Append the trained model to the list of models\n",
    "        y_pred = model.predict_proba(x_val) # Predict probabilities for the validation set for 4 classes\n",
    "        shape = y_val.size\n",
    "        \n",
    "        for i in range(shape):\n",
    "            pred_sets.append(y_pred[i])\n",
    "            true_sets.append(y_val[i])\n",
    "    \n",
    "    y_pred = np.array(pred_sets)\n",
    "    y_val = pd.Series(true_sets)\n",
    "    \n",
    "    print('Models', models)\n",
    "    \n",
    "    return models, y_pred, y_val   # Return the list of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39c2fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:38:51.257006Z",
     "iopub.status.busy": "2023-08-11T07:38:51.255516Z",
     "iopub.status.idle": "2023-08-11T07:39:17.536119Z",
     "shell.execute_reply": "2023-08-11T07:39:17.535214Z"
    },
    "papermill": {
     "duration": 26.290803,
     "end_time": "2023-08-11T07:39:17.538786",
     "exception": false,
     "start_time": "2023-08-11T07:38:51.247983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), TabPFNClassifier(N_ensemble_configurations=12, device='cuda'), TabPFNClassifier(N_ensemble_configurations=24, device='cuda'), RandomForestClassifier(max_depth=3, random_state=42)]\n",
      "fold 0\n",
      "0.0    102\n",
      "1.0     22\n",
      "Name: Class, dtype: int64\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "TabPFNClassifier(N_ensemble_configurations=12, device='cuda')\n",
      "TabPFNClassifier(N_ensemble_configurations=24, device='cuda')\n",
      "RandomForestClassifier(max_depth=3, random_state=42)\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), TabPFNClassifier(N_ensemble_configurations=12, device='cuda'), TabPFNClassifier(N_ensemble_configurations=24, device='cuda'), RandomForestClassifier(max_depth=3, random_state=42)]\n",
      "fold 1\n",
      "0.0    102\n",
      "1.0     22\n",
      "Name: Class, dtype: int64\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "TabPFNClassifier(N_ensemble_configurations=12, device='cuda')\n",
      "TabPFNClassifier(N_ensemble_configurations=24, device='cuda')\n",
      "RandomForestClassifier(max_depth=3, random_state=42)\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), TabPFNClassifier(N_ensemble_configurations=12, device='cuda'), TabPFNClassifier(N_ensemble_configurations=24, device='cuda'), RandomForestClassifier(max_depth=3, random_state=42)]\n",
      "fold 2\n",
      "0.0    101\n",
      "1.0     22\n",
      "Name: Class, dtype: int64\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "TabPFNClassifier(N_ensemble_configurations=12, device='cuda')\n",
      "TabPFNClassifier(N_ensemble_configurations=24, device='cuda')\n",
      "RandomForestClassifier(max_depth=3, random_state=42)\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), TabPFNClassifier(N_ensemble_configurations=12, device='cuda'), TabPFNClassifier(N_ensemble_configurations=24, device='cuda'), RandomForestClassifier(max_depth=3, random_state=42)]\n",
      "fold 3\n",
      "0.0    102\n",
      "1.0     21\n",
      "Name: Class, dtype: int64\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "TabPFNClassifier(N_ensemble_configurations=12, device='cuda')\n",
      "TabPFNClassifier(N_ensemble_configurations=24, device='cuda')\n",
      "RandomForestClassifier(max_depth=3, random_state=42)\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'tabpfn.scripts.transformer_prediction_interface.TabPFNClassifier'>\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Multiple models in memory. This might lead to memory issues. Consider calling remove_models_from_memory()\n",
      "cls: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...), TabPFNClassifier(N_ensemble_configurations=12, device='cuda'), TabPFNClassifier(N_ensemble_configurations=24, device='cuda'), RandomForestClassifier(max_depth=3, random_state=42)]\n",
      "fold 4\n",
      "0.0    102\n",
      "1.0     21\n",
      "Name: Class, dtype: int64\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.85, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor='gpu_predictor', random_state=None, ...)\n",
      "TabPFNClassifier(N_ensemble_configurations=12, device='cuda')\n",
      "TabPFNClassifier(N_ensemble_configurations=24, device='cuda')\n",
      "RandomForestClassifier(max_depth=3, random_state=42)\n",
      "Models [<__main__.Ensemble object at 0x7b12180f5ed0>, <__main__.Ensemble object at 0x7b121817b1c0>, <__main__.Ensemble object at 0x7b121817a9e0>, <__main__.Ensemble object at 0x7b121817a350>, <__main__.Ensemble object at 0x7b1218179b10>]\n"
     ]
    }
   ],
   "source": [
    "models, y_pred, y_val = training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dff76d",
   "metadata": {
    "papermill": {
     "duration": 0.012556,
     "end_time": "2023-08-11T07:39:17.565136",
     "exception": false,
     "start_time": "2023-08-11T07:39:17.552580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811013a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:39:17.591813Z",
     "iopub.status.busy": "2023-08-11T07:39:17.591451Z",
     "iopub.status.idle": "2023-08-11T07:39:21.077981Z",
     "shell.execute_reply": "2023-08-11T07:39:21.077063Z"
    },
    "papermill": {
     "duration": 3.50166,
     "end_time": "2023-08-11T07:39:21.080113",
     "exception": false,
     "start_time": "2023-08-11T07:39:17.578453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save RL_Model to file in the current working directory\n",
    "save_dir = '/kaggle/working/'\n",
    "\n",
    "joblib.dump(models, 'ensemble.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7a334e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:39:21.100734Z",
     "iopub.status.busy": "2023-08-11T07:39:21.099925Z",
     "iopub.status.idle": "2023-08-11T07:39:22.884018Z",
     "shell.execute_reply": "2023-08-11T07:39:22.883014Z"
    },
    "papermill": {
     "duration": 1.796527,
     "end_time": "2023-08-11T07:39:22.886348",
     "exception": false,
     "start_time": "2023-08-11T07:39:21.089821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Ensemble at 0x7b11b7e6fb80>,\n",
       " <__main__.Ensemble at 0x7b11ec0ae920>,\n",
       " <__main__.Ensemble at 0x7b11ffff2620>,\n",
       " <__main__.Ensemble at 0x7b1211d68fd0>,\n",
       " <__main__.Ensemble at 0x7b11b7c24040>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = joblib.load('/kaggle/working/ensemble.joblib')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93c41f",
   "metadata": {
    "papermill": {
     "duration": 0.010614,
     "end_time": "2023-08-11T07:39:22.906841",
     "exception": false,
     "start_time": "2023-08-11T07:39:22.896227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003cbf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:39:22.935111Z",
     "iopub.status.busy": "2023-08-11T07:39:22.934669Z",
     "iopub.status.idle": "2023-08-11T07:39:22.943605Z",
     "shell.execute_reply": "2023-08-11T07:39:22.942366Z"
    },
    "papermill": {
     "duration": 0.026519,
     "end_time": "2023-08-11T07:39:22.946484",
     "exception": false,
     "start_time": "2023-08-11T07:39:22.919965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(y_pred, y_val):    \n",
    "    ret = []\n",
    "    #find best threshold\n",
    "    for thres_1 in np.arange(0, 1, 0.01):\n",
    "        for thres_0 in np.arange(thres_1, 1, 0.01):\n",
    "            shape = len(y_val)\n",
    "            #post processing\n",
    "            y_p = calibrate_prob(y_pred, shape, thres_1, thres_0)\n",
    "\n",
    "            #balanced log loss\n",
    "            loss = balanced_log_loss(y_val, y_p)  # Calculate the balanced log loss between the predicted labels and the true labels\n",
    "\n",
    "    #         # checking\n",
    "    #         y_val = y_val.to_frame()\n",
    "    #         y_val.rename(columns = {'Class': 'gt'}, inplace = True)\n",
    "    #         y_val['pred'] = y_p[:, 1]\n",
    "    # #         print(type(y_val['gt']), type(y_val.loc[0, 'gt']), type(y_val['pred']), type(y_val.loc[0, 'pred']))\n",
    "    #         p00 = y_p[:, 1]\n",
    "    #         p00 = p00.flatten()\n",
    "    #         y_val['prob'] = p00\n",
    "    #         display(y_val)\n",
    "#             print('>LOSS=%.5f' % loss)\n",
    "            ret.append([thres_1, thres_0, loss])\n",
    "    \n",
    "    ret = sorted(ret, key= lambda x: x[2])\n",
    "    print('best:\\n', ret[:10])\n",
    "    \n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085789fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:39:22.972593Z",
     "iopub.status.busy": "2023-08-11T07:39:22.972244Z",
     "iopub.status.idle": "2023-08-11T07:39:28.080287Z",
     "shell.execute_reply": "2023-08-11T07:39:28.078911Z"
    },
    "papermill": {
     "duration": 5.12398,
     "end_time": "2023-08-11T07:39:28.082472",
     "exception": false,
     "start_time": "2023-08-11T07:39:22.958492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:\n",
      " [[0.02, 0.7799999999999999, 0.17258183678220163], [0.01, 0.78, 0.17323194573237058], [0.0, 0.78, 0.17325830445591411], [0.02, 0.7899999999999999, 0.17545138596028972], [0.01, 0.79, 0.17610149491045868], [0.0, 0.79, 0.1761278536340022], [0.02, 0.7999999999999999, 0.1775410710459487], [0.01, 0.8, 0.17819117999611764], [0.0, 0.8, 0.1782175387196612], [0.02, 0.8099999999999999, 0.17952269093263262]]\n"
     ]
    }
   ],
   "source": [
    "best_thres = evaluation(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263633f",
   "metadata": {
    "papermill": {
     "duration": 0.011623,
     "end_time": "2023-08-11T07:39:28.105926",
     "exception": false,
     "start_time": "2023-08-11T07:39:28.094303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4478c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:39:28.129176Z",
     "iopub.status.busy": "2023-08-11T07:39:28.128580Z",
     "iopub.status.idle": "2023-08-11T07:39:28.135976Z",
     "shell.execute_reply": "2023-08-11T07:39:28.135020Z"
    },
    "papermill": {
     "duration": 0.020979,
     "end_time": "2023-08-11T07:39:28.137949",
     "exception": false,
     "start_time": "2023-08-11T07:39:28.116970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/thres.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_thres, '/kaggle/working/thres.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.704774,
   "end_time": "2023-08-11T07:39:31.076570",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-11T07:38:17.371796",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
